# HTTP/0.9

HTTP/0.9是第一个版本的HTTP协议，已过时。它的组成极其简单，只允许客户端发送GET这一种请求，且不支持请求头。由于没有协议头，造成了HTTP/0.9协议只支持一种内容，即纯文本。不过网页仍然支持用HTML语言格式化，同时无法插入图片。

HTTP/0.9具有典型的无状态性，每个事务独立进行处理，事务结束时就释放这个连接。由此可见，HTTP协议的无状态特点在其第一个版本0.9中已经成型。一次HTTP/0.9的传输首先要建立一个由客户端到web服务器的TCP连接，由客户端发起一个请求，然后由web服务器返回页面内容，然后连接会关闭。如果请求的页面不存在，也不会返回任何状态码。

# HTTP/1.0

HTTP/1.0增加了如下几个变化：

* 增加了 HTTP 版本号；
* 增加了请求方法，支持 GET、HEAD、POST 方法；
* 增加了 header 请求头，不管是request还是response 都有 header 了；
* 增加了状态码，响应对象以一个响应状态码开始；
* 增加了 Content-Type 请求头，响应对象不再只限于超文本，可以传输其它的文件了；

HTTP/1.0存在的问题：

* **短连接：** HTTP/1.0 被设计用来使用短连接，每次发送请求，都需要进行一次 TCP 连接，即每次发送数据都会经过 TCP 的三次握手和四次挥手，效率比较低，HTTP/1.0 需要设置 Connection 请求头的值为 Keep-Alive 来告知服务器端要建立一个长连接。
* **队首阻塞（head of line blocking）：** 由于 HTTP/1.0 规定下一个请求必须在前一个请求响应到达之前才能发送，如果前一个请求响应一直不到达，那么下一个请求就不发送，后面的请求就阻塞了。
* **缓存机制：** HTTP/1.0 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。
* **浪费带宽：** HTTP/1.0 不支持断点续传，也就是说，每次都会传送全部的页面和数据。
* **HOST 域：** HTTP/1.0 认为每台计算机都绑定一个唯一的 IP 地址，所以请求消息中的 URL 并没有传递主机名（hostname），HTTP/1.0 是没有 HOST 域的。

# HTTP/1.1

* **新增请求方法：** 正式加入了 OPTIONS 请求方法。
* **新增状态码：** 在 HTTP/1.1 中新增了 24 个错误状态响应码，如：409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
* **长连接：** 在 HTTP/1.1 中默认开启长连接 keep-alive，支持长连接和请求的流水线处理，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟。
* **节约带宽：** HTTP/1.1 支持只发送 header 信息（不带任何 body 信息），如果服务器认为客户端有权限请求服务器，则返回 100 状态码，客户端接收到 100 才开始把请求 body 发送到服务器；如果返回 401，客户端就可以不用发送请求 body 了，节约了带宽。另外 HTTP 还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。
* **HOST域：** 随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址，HTTP/1.1 的请求消息和响应消息都支持 HOST 域，且请求消息中如果没有 HOST 域会报告一个错误（400 Bad Request）。
* **缓存机制：** HTTP/1.1 支持 cache control 机制，且引入了更多的缓存控制策略例如 E-tag、If-Unmodified-Since、If-Match、If-None-Match 等更多可供选择的缓存头来控制缓存策略。
* **管道化（pipelining）：** 在长连接的基础上，HTTP/1.1 进一步地支持管道化（pipelining）特性。在响应到达之前，可以将多条请求放入队列，当第一条请求发往服务器的时候，第二第三条请求也可以开始发送了，不用等到第一条请求响应回来，在高延时网络条件下，这样做可以降低网络的环回时间，提高性能。但是，服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容。服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求需要先响应回来。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送，也会造成队首阻塞，相应的阻塞。

# HTTP/2.0

* **头部压缩：** HTTP/2.0 使用算法对 header 的数据进行压缩，通讯双方各自缓存一份 header_files 表，既避免重复 header 的传输，又减少了需要传输的大小。
* **服务器推送：** 服务端推送是一种在客户端请求之前发送数据的机制。当客户端对支持 HTTP/2.0 的 web server 请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。服务器推送可以缓存，并且在遵循同源的情况下，不同页面之间可以共享缓存。因此当客户端需要的数据已缓存时，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。
* **二进制分帧：** HTTP/2.0 在应用层和传输层之间增加了一个二进制分层帧，突破了 HTTP/1.1 的性能限制，改进传输性能。HTTP/2.0 是一个彻底的二进制协议，头信息和数据体都是二进制的，并且统称为”帧“，可以分为 HEADERS 帧和 DATA 帧。
* **多路复用：** 所有 HTTP/2.0 通信都在一个 TCP 连接上完成，在一个连接里，客户端和服务器都可以同时发送多个请求或回应，而且不用按照顺序一一发送，这样就避免了”队头堵塞“的问题。单个 TCP 连接可以承载任意流量的双向数据流，每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符（Stream_id）重新封装。同个域名只需要占用一个 TCP 连接，使用一个连接并行发送多个请求和响应,这样整个页面资源的下载过程只需要一次慢启动，同时也避免了多个 TCP 连接竞争带宽所带来的问题。
* **请求优先级：** 在 HTTP/2.0 中，每个请求都可以带一个 31 bit 的优先值，0 表示最高优先级， 数值越大优先级越低。有了这个优先值，客户端和服务器就可以在处理不同的流时采取不同的策略，如果流被赋予了优先级，它就会基于这个优先级来处理，由服务器决定需要多少资源来处理该请求，并以最优的方式发送流、消息和帧。

**问题：** 多路复用的"线头阻塞"，多个数据请求作为不同的流，共用一条 TCP 连接发送，所有的流应用层都必须按序处理。若某个流的数据丢失，后面其他流的数据都会被阻塞，直到丢失的流数据重传完成其他流才能被继续传输。即使接收端已经收到之后流的数据包，HTTP协议也不会通知应用层去处理。

# HTTP/3.0

HTTP/3.0 的核心是 QUIC 协议，QUIC 是基于 UDP 协议的。

* **0-RTT：** 减少了 TCP 三次握手及 TLS 握手时间，基于 UDP 协议的 QUIC，因为 UDP 本身没有连接的概念，连接建立时只需要一次交互。而且缓存当前会话的上下文，下次恢复会话的时候，只需要将之前的缓存传递给服务器，验证通过，就可以进行传输了。传输层和加密层 0-RTT 就都能建立连接。
* **解决线头阻塞问题：** 解决了 HTTP/2.0 中前一个 stream 丢包导致后一个 stream 被阻塞的问题，QUIC 中一个连接上的多个 stream 之间没有依赖，所以当发生丢包时，只会影响当前的 stream，也就避免了线头阻塞问题。
* **优化重传策略：** 重传包和原包的编号不同，这样发送端每次在收到 ACK 时，就可以依据编号明确的判断这个 ACK 是来自初始封包或者是重传封包，降低后续重传计算的消耗。
* **连接迁移：** 不再用 TCP 四元组确定一个连接，而是用一个64位随机数来确定这个连接，这样即使切换到一个新网络，IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。
* **流量控制：** 采用了连线层（connection flow control）和 Stream 层的（streamflow control）流量控制，限制单一 Stream 可以占用的最大 buffer size。